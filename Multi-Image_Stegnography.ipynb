{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchviz import make_dot\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'E:\\Python Programs\\Datasets\\imagenette2-320\\Train\\Set'\n",
    "train_csv = 'E:\\Python Programs\\Datasets\\imagenette2-320\\Train\\Set\\Train_dataset.csv'\n",
    "valid_csv = 'E:\\Python Programs\\Datasets\\imagenette2-320\\Train\\Set\\Validation_dataset.csv'\n",
    "train_folder = 'E:\\Python Programs\\Datasets\\imagenette2-320\\Tr'\n",
    "validation_folder = 'E:\\Python Programs\\Datasets\\imagenette2-320\\Vl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "LEARNING_RATE = 0.005\n",
    "COVER_LOSS_WEIGHT = 1\n",
    "SECRET_LOSS_WEIGHT = 1\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 1\n",
    "EPOCHS = 500\n",
    "DECODER_LOSS_WEIGHT = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.transforms' has no attribute 'Resize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18312/3415667041.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m transformations = {\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;34m'train_transforms'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;34m'valid_transforms'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m }\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torchvision.transforms' has no attribute 'Resize'"
     ]
    }
   ],
   "source": [
    "transformations = {\n",
    "    'train_transforms': torchvision.transforms.Compose([torchvision.transforms.Resize((IMG_SIZE, IMG_SIZE)), torchvision.transforms.ToTensor()]),\n",
    "    'valid_transforms': torchvision.transforms.Compose([torchvision.transforms.Resize((IMG_SIZE, IMG_SIZE)), torchvision.transforms.ToTensor()])\n",
    "}\n",
    "\n",
    "\n",
    "class SteganoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_csv, transforms, type_of_dataset, size='complete'):\n",
    "        self.dataset = pd.read_csv(dataset_csv)\n",
    "        self.dataset = self.dataset.reset_index(drop=True)\n",
    "        if size != 'complete':\n",
    "            self.dataset = self.dataset[:4]\n",
    "        self.transforms = transforms\n",
    "        self.type = type_of_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        cover_image = self.dataset.iloc[index]['cover_image']\n",
    "        secret_image1 = self.dataset.iloc[index]['secret_image_1']\n",
    "        secret_image2 = self.dataset.iloc[index]['secret_image_2']\n",
    "        secret_image3 = self.dataset.iloc[index]['secret_image_3']\n",
    "\n",
    "        cover_image = Image.open(os.path.join(\n",
    "            dataset_path, self.type, cover_image))\n",
    "        secret_image1 = Image.open(os.path.join(\n",
    "            dataset_path, self.type, secret_image1))\n",
    "        secret_image2 = Image.open(os.path.join(\n",
    "            dataset_path, self.type, secret_image2))\n",
    "        secret_image3 = Image.open(os.path.join(\n",
    "            dataset_path, self.type, secret_image3))\n",
    "\n",
    "        transformed_cover_image = self.transforms(cover_image)\n",
    "        transformed_secret_image_1 = self.transforms(secret_image1)\n",
    "        transformed_secret_image_2 = self.transforms(secret_image2)\n",
    "        transformed_secret_image_3 = self.transforms(secret_image3)\n",
    "\n",
    "        if self.type == 'train':\n",
    "            return {\n",
    "                'cover_image': transformed_cover_image,\n",
    "                'secret_image_1': transformed_secret_image_1,\n",
    "                'secret_image_2': transformed_secret_image_2,\n",
    "                'secret_image_3': transformed_secret_image_3\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'cover_image': transformed_cover_image,\n",
    "                'secret_image_1': transformed_secret_image_1,\n",
    "                'secret_image_2': transformed_secret_image_2,\n",
    "                'secret_image_3': transformed_secret_image_3\n",
    "            }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepNetwork1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrepNetwork1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "    def forward(self, secret_image):\n",
    "        output_1 = F.relu(self.conv1(secret_image))\n",
    "        output_2 = F.relu(self.conv2(secret_image))\n",
    "        output_3 = F.relu(self.conv3(secret_image))\n",
    "\n",
    "        concatenated_image = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "        output_4 = F.relu(self.conv4(concatenated_image))\n",
    "        output_5 = F.relu(self.conv5(concatenated_image))\n",
    "        output_6 = F.relu(self.conv6(concatenated_image))\n",
    "\n",
    "        final_concat_image = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "        return final_concat_image\n",
    "\n",
    "\n",
    "class PrepNetwork2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrepNetwork2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "    def forward(self, secret_image):\n",
    "        output_1 = F.relu(self.conv1(secret_image))\n",
    "        output_2 = F.relu(self.conv2(secret_image))\n",
    "        output_3 = F.relu(self.conv3(secret_image))\n",
    "\n",
    "        concatenated_image = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "        output_4 = F.relu(self.conv4(concatenated_image))\n",
    "        output_5 = F.relu(self.conv5(concatenated_image))\n",
    "        output_6 = F.relu(self.conv6(concatenated_image))\n",
    "\n",
    "        final_concat_image = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "        return final_concat_image\n",
    "\n",
    "\n",
    "class PrepNetwork3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrepNetwork3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "    def forward(self, secret_image):\n",
    "        output_1 = F.relu(self.conv1(secret_image))\n",
    "        output_2 = F.relu(self.conv2(secret_image))\n",
    "        output_3 = F.relu(self.conv3(secret_image))\n",
    "\n",
    "        concatenated_image = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "        output_4 = F.relu(self.conv4(concatenated_image))\n",
    "        output_5 = F.relu(self.conv5(concatenated_image))\n",
    "        output_6 = F.relu(self.conv6(concatenated_image))\n",
    "\n",
    "        final_concat_image = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "        return final_concat_image\n",
    "\n",
    "\n",
    "class HidingNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HidingNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=198, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=198, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=198, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv13 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv14 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv15 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(\n",
    "            in_channels=65, out_channels=3, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "    def forward(self, secret_image_1, secret_image_2, secret_image_3, cover_image):\n",
    "        concatenated_secrets = torch.cat(\n",
    "            [cover_image, secret_image_1, secret_image_2, secret_image_3], dim=1)\n",
    "\n",
    "        output_1 = F.relu(self.conv1(concatenated_secrets))\n",
    "        output_2 = F.relu(self.conv2(concatenated_secrets))\n",
    "        output_3 = F.relu(self.conv3(concatenated_secrets))\n",
    "        concat_1 = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "\n",
    "        output_4 = F.relu(self.conv4(concat_1))\n",
    "        output_5 = F.relu(self.conv5(concat_1))\n",
    "        output_6 = F.relu(self.conv6(concat_1))\n",
    "        concat_2 = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "\n",
    "        output_7 = F.relu(self.conv7(concat_2))\n",
    "        output_8 = F.relu(self.conv8(concat_2))\n",
    "        output_9 = F.relu(self.conv9(concat_2))\n",
    "        concat_3 = torch.cat([output_7, output_8, output_9], dim=1)\n",
    "\n",
    "        output_10 = F.relu(self.conv10(concat_3))\n",
    "        output_11 = F.relu(self.conv11(concat_3))\n",
    "        output_12 = F.relu(self.conv12(concat_3))\n",
    "        concat_4 = torch.cat([output_10, output_11, output_12], dim=1)\n",
    "\n",
    "        output_13 = F.relu(self.conv13(concat_4))\n",
    "        output_14 = F.relu(self.conv14(concat_4))\n",
    "        output_15 = F.relu(self.conv15(concat_4))\n",
    "        concat_5 = torch.cat([output_13, output_14, output_15], dim=1)\n",
    "\n",
    "        output_converted_image = F.relu(self.final_layer(concat_5))\n",
    "\n",
    "        return output_converted_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, prep_network_1, prep_network_2, prep_network_3, hiding_network):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.prep_network1 = prep_network_1\n",
    "        self.prep_network2 = prep_network_2\n",
    "        self.prep_network3 = prep_network_3\n",
    "        self.hiding_network = hiding_network\n",
    "\n",
    "    def forward(self, cover_image, secret_image_1, secret_image_2, secret_image_3):\n",
    "        encoded_secret_image_1 = self.prep_network1(secret_image_1)\n",
    "        encoded_secret_image_2 = self.prep_network2(secret_image_2)\n",
    "        encoded_secret_image_3 = self.prep_network3(secret_image_3)\n",
    "\n",
    "        hidden_image = self.hiding_network(encoded_secret_image_1,\n",
    "                                           encoded_secret_image_2,\n",
    "                                           encoded_secret_image_3,\n",
    "                                           cover_image\n",
    "                                           )\n",
    "#         hidden_image = (0.01**0.5)*torch.randn(hidden_image.size(),device=device)\n",
    "        return hidden_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevealNetwork1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RevealNetwork1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv13 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv14 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv15 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(\n",
    "            in_channels=65, out_channels=3, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "    def forward(self, hidden_image):\n",
    "\n",
    "        output_1 = F.relu(self.conv1(hidden_image))\n",
    "        output_2 = F.relu(self.conv2(hidden_image))\n",
    "        output_3 = F.relu(self.conv3(hidden_image))\n",
    "        concat_1 = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "\n",
    "        output_4 = F.relu(self.conv4(concat_1))\n",
    "        output_5 = F.relu(self.conv5(concat_1))\n",
    "        output_6 = F.relu(self.conv6(concat_1))\n",
    "        concat_2 = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "\n",
    "        output_7 = F.relu(self.conv7(concat_2))\n",
    "        output_8 = F.relu(self.conv8(concat_2))\n",
    "        output_9 = F.relu(self.conv9(concat_2))\n",
    "        concat_3 = torch.cat([output_7, output_8, output_9], dim=1)\n",
    "\n",
    "        output_10 = F.relu(self.conv10(concat_3))\n",
    "        output_11 = F.relu(self.conv11(concat_3))\n",
    "        output_12 = F.relu(self.conv12(concat_3))\n",
    "        concat_4 = torch.cat([output_10, output_11, output_12], dim=1)\n",
    "\n",
    "        output_13 = F.relu(self.conv13(concat_4))\n",
    "        output_14 = F.relu(self.conv14(concat_4))\n",
    "        output_15 = F.relu(self.conv15(concat_4))\n",
    "        concat_5 = torch.cat([output_13, output_14, output_15], dim=1)\n",
    "\n",
    "        output_revealed_image = F.relu(self.final_layer(concat_5))\n",
    "\n",
    "        return output_revealed_image\n",
    "\n",
    "\n",
    "class RevealNetwork2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RevealNetwork2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv13 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv14 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv15 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(\n",
    "            in_channels=65, out_channels=3, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "    def forward(self, hidden_image):\n",
    "\n",
    "        output_1 = F.relu(self.conv1(hidden_image))\n",
    "        output_2 = F.relu(self.conv2(hidden_image))\n",
    "        output_3 = F.relu(self.conv3(hidden_image))\n",
    "        concat_1 = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "\n",
    "        output_4 = F.relu(self.conv4(concat_1))\n",
    "        output_5 = F.relu(self.conv5(concat_1))\n",
    "        output_6 = F.relu(self.conv6(concat_1))\n",
    "        concat_2 = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "\n",
    "        output_7 = F.relu(self.conv7(concat_2))\n",
    "        output_8 = F.relu(self.conv8(concat_2))\n",
    "        output_9 = F.relu(self.conv9(concat_2))\n",
    "        concat_3 = torch.cat([output_7, output_8, output_9], dim=1)\n",
    "\n",
    "        output_10 = F.relu(self.conv10(concat_3))\n",
    "        output_11 = F.relu(self.conv11(concat_3))\n",
    "        output_12 = F.relu(self.conv12(concat_3))\n",
    "        concat_4 = torch.cat([output_10, output_11, output_12], dim=1)\n",
    "\n",
    "        output_13 = F.relu(self.conv13(concat_4))\n",
    "        output_14 = F.relu(self.conv14(concat_4))\n",
    "        output_15 = F.relu(self.conv15(concat_4))\n",
    "        concat_5 = torch.cat([output_13, output_14, output_15], dim=1)\n",
    "\n",
    "        output_revealed_image = F.relu(self.final_layer(concat_5))\n",
    "\n",
    "        return output_revealed_image\n",
    "\n",
    "\n",
    "class RevealNetwork3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RevealNetwork3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv13 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv14 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv15 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(\n",
    "            in_channels=65, out_channels=3, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "    def forward(self, hidden_image):\n",
    "        output_1 = F.relu(self.conv1(hidden_image))\n",
    "        output_2 = F.relu(self.conv2(hidden_image))\n",
    "        output_3 = F.relu(self.conv3(hidden_image))\n",
    "        concat_1 = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "\n",
    "        output_4 = F.relu(self.conv4(concat_1))\n",
    "        output_5 = F.relu(self.conv5(concat_1))\n",
    "        output_6 = F.relu(self.conv6(concat_1))\n",
    "        concat_2 = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "\n",
    "        output_7 = F.relu(self.conv7(concat_2))\n",
    "        output_8 = F.relu(self.conv8(concat_2))\n",
    "        output_9 = F.relu(self.conv9(concat_2))\n",
    "        concat_3 = torch.cat([output_7, output_8, output_9], dim=1)\n",
    "\n",
    "        output_10 = F.relu(self.conv10(concat_3))\n",
    "        output_11 = F.relu(self.conv11(concat_3))\n",
    "        output_12 = F.relu(self.conv12(concat_3))\n",
    "        concat_4 = torch.cat([output_10, output_11, output_12], dim=1)\n",
    "\n",
    "        output_13 = F.relu(self.conv13(concat_4))\n",
    "        output_14 = F.relu(self.conv14(concat_4))\n",
    "        output_15 = F.relu(self.conv15(concat_4))\n",
    "        concat_5 = torch.cat([output_13, output_14, output_15], dim=1)\n",
    "\n",
    "        output_revealed_image = F.relu(self.final_layer(concat_5))\n",
    "\n",
    "        return output_revealed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, reveal_network_1, reveal_network_2, reveal_network_3):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.reveal_network_1 = reveal_network_1\n",
    "        self.reveal_network_2 = reveal_network_2\n",
    "        self.reveal_network_3 = reveal_network_3\n",
    "\n",
    "    def forward(self, hidden_image):\n",
    "        reveal_image_1 = self.reveal_network_1(hidden_image)\n",
    "        reveal_image_2 = self.reveal_network_2(hidden_image)\n",
    "        reveal_image_3 = self.reveal_network_3(hidden_image)\n",
    "        return reveal_image_1, reveal_image_2, reveal_image_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteganoModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(SteganoModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, cover_image, secret_image_1, secret_image_2, secret_image_3, hidden_image, mode):\n",
    "        if mode == 'full':\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in self.decoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            hidden_image = self.encoder(\n",
    "                cover_image, secret_image_1, secret_image_2, secret_image_3)\n",
    "            reveal_image_1, reveal_image_2, reveal_image_3 = self.decoder(\n",
    "                hidden_image)\n",
    "            return hidden_image, reveal_image_1, reveal_image_2, reveal_image_3\n",
    "        elif mode == 'encoder':\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.decoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            hidden_image = self.encoder(\n",
    "                cover_image, secret_image_1, secret_image_2, secret_image_3)\n",
    "            return hidden_image\n",
    "        elif mode == 'decoder':\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.decoder.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            reveal_image1, reveal_image2, reveal_image3 = self.decoder(\n",
    "                hidden_image)\n",
    "            return reveal_image1, reveal_image2, reveal_image3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SteganoModel(\n",
       "  (encoder): Encoder(\n",
       "    (prep_network1): PrepNetwork1(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (prep_network2): PrepNetwork2(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (prep_network3): PrepNetwork3(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (hiding_network): HidingNetwork(\n",
       "      (conv1): Conv2d(198, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(198, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(198, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv7): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv8): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv9): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv10): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv11): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv12): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv13): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv14): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv15): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (final_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (reveal_network_1): RevealNetwork1(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv7): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv8): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv9): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv10): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv11): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv12): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv13): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv14): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv15): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (final_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (reveal_network_2): RevealNetwork2(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv7): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv8): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv9): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv10): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv11): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv12): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv13): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv14): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv15): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (final_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (reveal_network_3): RevealNetwork3(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv7): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv8): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv9): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv10): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv11): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv12): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv13): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv14): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv15): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (final_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_1 = PrepNetwork1()\n",
    "prep_2 = PrepNetwork2()\n",
    "prep_3 = PrepNetwork3()\n",
    "hiding_network = HidingNetwork()\n",
    "\n",
    "encoder = Encoder(prep_1, prep_2, prep_3, hiding_network)\n",
    "\n",
    "reveal_1 = RevealNetwork1()\n",
    "reveal_2 = RevealNetwork2()\n",
    "reveal_3 = RevealNetwork3()\n",
    "\n",
    "decoder = Decoder(reveal_1, reveal_2, reveal_3)\n",
    "\n",
    "model = SteganoModel(encoder, decoder)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteganoLoss(nn.Module):\n",
    "    def __init__(self, cover_weight, secret_weight):\n",
    "        super(SteganoLoss, self).__init__()\n",
    "        self.cover_weight = cover_weight\n",
    "        self.secret_weight = secret_weight\n",
    "\n",
    "    def forward(self, predicted_cover_image, cover_image,\n",
    "                predicted_secret_image_1, secret_image_1,\n",
    "                predicted_secret_image_2, secret_image_2,\n",
    "                predicted_secret_image_3, secret_image_3):\n",
    "\n",
    "        cover_loss = self.cover_weight * \\\n",
    "            (F.mse_loss(predicted_cover_image, cover_image))\n",
    "        secret_loss = self.secret_weight*(F.mse_loss(predicted_secret_image_1, secret_image_1)) + self.secret_weight*(F.mse_loss(\n",
    "            predicted_secret_image_2, secret_image_2)) + self.secret_weight*(F.mse_loss(predicted_secret_image_3, secret_image_3))\n",
    "        return cover_loss + secret_loss\n",
    "\n",
    "\n",
    "class DecoderLoss(nn.Module):\n",
    "    def __init__(self, decoder_loss_weight):\n",
    "        super(DecoderLoss, self).__init__()\n",
    "        self.decoder_loss_weight = decoder_loss_weight\n",
    "\n",
    "    def forward(self, reveal_output1, reveal_output2, reveal_output3, secret_image_1,\n",
    "                secret_image_2, secret_image_3):\n",
    "        reveal1 = self.decoder_loss_weight * \\\n",
    "            F.mse_loss(reveal_output1, secret_image_1)\n",
    "        reveal2 = self.decoder_loss_weight * \\\n",
    "            F.mse_loss(reveal_output2, secret_image_2)\n",
    "        reveal3 = self.decoder_loss_weight * \\\n",
    "            F.mse_loss(reveal_output3, secret_image_3)\n",
    "\n",
    "        return reveal1 + reveal2 + reveal3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv_path = os.path.join(dataset_path, train_csv)\n",
    "validation_csv_path = os.path.join(dataset_path, valid_csv)\n",
    "\n",
    "training_dataset = SteganoDataset(\n",
    "    training_csv_path, transformations['train_transforms'], 'train', 'complete')\n",
    "valid_dataset = SteganoDataset(\n",
    "    validation_csv_path, transformations['valid_transforms'], 'valid')\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(training_dataset,\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                num_workers=0\n",
    "                                                )\n",
    "valid_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                                batch_size=VALID_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                num_workers=0\n",
    "                                                )\n",
    "\n",
    "full_model_criterion = SteganoLoss(SECRET_LOSS_WEIGHT, COVER_LOSS_WEIGHT)\n",
    "\n",
    "full_model_optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "decoder_criterion = DecoderLoss(DECODER_LOSS_WEIGHT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, decoder_criterion, full_model_optimizer, full_model_criterion, learning_rate, training_iterator, valid_iterator, print_every=50):\n",
    "\n",
    "    training_full_model_loss_list = []\n",
    "    decoder_loss_list = []\n",
    "    valid_loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for index, training_dict in enumerate(training_iterator):\n",
    "            cover_image = training_dict['cover_image']\n",
    "            cover_image = cover_image.to(device)\n",
    "\n",
    "            secret_image_1 = training_dict['secret_image_1']\n",
    "            secret_image_1 = secret_image_1.to(device)\n",
    "\n",
    "            secret_image_2 = training_dict['secret_image_2']\n",
    "            secret_image_2 = secret_image_2.to(device)\n",
    "\n",
    "            secret_image_3 = training_dict['secret_image_3']\n",
    "            secret_image_3 = secret_image_3.to(device)\n",
    "\n",
    "            full_model_optimizer.zero_grad()\n",
    "\n",
    "            encoder_output = model(\n",
    "                cover_image, secret_image_1, secret_image_2, secret_image_3, secret_image_3, 'encoder')\n",
    "\n",
    "            hidden_image, reveal_image_1, reveal_image_2, reveal_image_3 = model(cover_image,\n",
    "                                                                                 secret_image_1,\n",
    "                                                                                 secret_image_2,\n",
    "                                                                                 secret_image_3, secret_image_3, 'full')\n",
    "\n",
    "            full_model_loss = full_model_criterion(hidden_image, cover_image,\n",
    "                                                   reveal_image_1, secret_image_1,\n",
    "                                                   reveal_image_2, secret_image_2,\n",
    "                                                   reveal_image_3, secret_image_3,\n",
    "                                                   )\n",
    "            full_model_loss.backward()\n",
    "            full_model_optimizer.step()\n",
    "\n",
    "            full_model_optimizer.zero_grad()\n",
    "            reveal_output1, reveal_output2, reveal_output3 = model(cover_image,\n",
    "                                                                   secret_image_1,\n",
    "                                                                   secret_image_2,\n",
    "                                                                   secret_image_3, encoder_output, 'decoder')\n",
    "            decoder_loss = decoder_criterion(reveal_output1, reveal_output2, reveal_output3, secret_image_1,\n",
    "                                             secret_image_2, secret_image_3)\n",
    "\n",
    "            decoder_loss.backward()\n",
    "            full_model_optimizer.step()\n",
    "\n",
    "        training_full_model_loss_list.append(full_model_loss)\n",
    "        decoder_loss_list.append(decoder_loss)\n",
    "        if epoch % print_every == 0:\n",
    "            print(\"Training full model loss at {} epochs is: {}\".format(\n",
    "                epoch, full_model_loss))\n",
    "            print(\"Training decoder loss at {} epochs is: {}\".format(\n",
    "                epoch, decoder_loss))\n",
    "\n",
    "    return model, training_full_model_loss_list, decoder_loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 64, 64] at entry 0 and [1, 64, 64] at entry 8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10796/88329715.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model, training_full_model_loss_list, decoder_loss_list = train(\n\u001b[0m\u001b[0;32m      2\u001b[0m     model, EPOCHS, decoder_criterion, full_model_optimizer, full_model_criterion, LEARNING_RATE, train_data_loader, valid_data_loader)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10796/933973223.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, decoder_criterion, full_model_optimizer, full_model_criterion, learning_rate, training_iterator, valid_iterator, print_every)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_dict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mcover_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cover_image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mcover_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcover_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_fields'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# namedtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_fields'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# namedtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 64, 64] at entry 0 and [1, 64, 64] at entry 8"
     ]
    }
   ],
   "source": [
    "model, training_full_model_loss_list, decoder_loss_list = train(\n",
    "    model, EPOCHS, decoder_criterion, full_model_optimizer, full_model_criterion, LEARNING_RATE, train_data_loader, valid_data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(valid_data_loader))\n",
    "\n",
    "cover_image = data['cover_image']\n",
    "cover_image = cover_image.to(device)\n",
    "\n",
    "secret_image_1 = data['secret_image_1']\n",
    "secret_image_1 = secret_image_1.to(device)\n",
    "\n",
    "secret_image_2 = data['secret_image_2']\n",
    "secret_image_2 = secret_image_2.to(device)\n",
    "\n",
    "secret_image_3 = data['secret_image_3']\n",
    "secret_image_3 = secret_image_3.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "hidden_image, reveal_image_1, reveal_image_2, reveal_image_3 = model(cover_image,\n",
    "                                                                     secret_image_1,\n",
    "                                                                     secret_image_2,\n",
    "                                                                     secret_image_3, secret_image_3, 'full')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hidden_image.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(hidden_image).render('hidden_image', format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reveal_image.png'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(reveal_image_1).render('reveal_image', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss_list, title):\n",
    "    plt.plot(loss_list)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_full_model_loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18260/2752312711.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_full_model_loss_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'training_full_model_loss_list' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss(training_full_model_loss_list)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c66f6a286164178c61090f11fff7531913209fa14f0a93186ebc32286e28675"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
