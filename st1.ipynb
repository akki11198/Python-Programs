{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Python Programs\\st1.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python%20Programs/st1.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Python%20Programs/st1.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python%20Programs/st1.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python%20Programs/st1.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchviz import make_dot\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"D:\\Python Programs\\Datasets\\imagenette2-320\\Train\\Set\\Train\"\n",
    "train_csv = \"D:\\Python Programs\\Datasets\\Train_dataset.csv\"\n",
    "valid_csv = \"D:\\Python Programs\\Datasets\\Validation_dataset.csv\"\n",
    "train_folder = \"D:\\Python Programs\\Datasets\\imagenette2-320\\Tr\"\n",
    "validation_folder = \"D:\\Python Programs\\Datasets\\imagenette2-320\\Vl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "COVER_LOSS_WEIGHT = 1\n",
    "SECRET_LOSS_WEIGHT = 1\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 1\n",
    "EPOCHS = 1000\n",
    "DECODER_LOSS_WEIGHT = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    'train_transforms':torchvision.transforms.Compose([torchvision.transforms.Resize((IMG_SIZE,IMG_SIZE)),torchvision.transforms.ToTensor()]),\n",
    "    'valid_transforms':torchvision.transforms.Compose([torchvision.transforms.Resize((IMG_SIZE,IMG_SIZE)),torchvision.transforms.ToTensor()])\n",
    "}\n",
    "\n",
    "class SteganoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,dataset_csv,transforms,type_of_dataset,size='complete'):\n",
    "        self.dataset = pd.read_csv(dataset_csv)\n",
    "        self.dataset = self.dataset.reset_index(drop=True)\n",
    "        if size !='complete':\n",
    "            self.dataset = self.dataset[:4]\n",
    "        self.transforms = transforms\n",
    "        self.type = type_of_dataset\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        cover_image = self.dataset.iloc[index]['cover_image']\n",
    "        secret_image1 = self.dataset.iloc[index]['secret_image_1']\n",
    "        secret_image2 = self.dataset.iloc[index]['secret_image_2']\n",
    "        secret_image3 = self.dataset.iloc[index]['secret_image_3']\n",
    "        \n",
    "        cover_image = Image.open(os.path.join(dataset_path,self.type,cover_image))\n",
    "        secret_image1 = Image.open(os.path.join(dataset_path,self.type,secret_image1))\n",
    "        secret_image2 = Image.open(os.path.join(dataset_path,self.type,secret_image2))\n",
    "        secret_image3 = Image.open(os.path.join(dataset_path,self.type,secret_image3))\n",
    "        \n",
    "        transformed_cover_image = self.transforms(cover_image)\n",
    "        transformed_secret_image_1 = self.transforms(secret_image1)\n",
    "        transformed_secret_image_2 = self.transforms(secret_image2)\n",
    "        transformed_secret_image_3 = self.transforms(secret_image3)\n",
    "        \n",
    "        if self.type == 'train':\n",
    "            return {\n",
    "                'cover_image':transformed_cover_image,\n",
    "                'secret_image_1':transformed_secret_image_1,\n",
    "                'secret_image_2':transformed_secret_image_2,\n",
    "                'secret_image_3':transformed_secret_image_3\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'cover_image':transformed_cover_image,\n",
    "                'secret_image_1':transformed_secret_image_1,\n",
    "                'secret_image_2':transformed_secret_image_2,\n",
    "                'secret_image_3':transformed_secret_image_3\n",
    "            }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepNetwork1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrepNetwork1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "    def forward(self, secret_image):\n",
    "        output_1 = F.relu(self.conv1(secret_image))\n",
    "        output_2 = F.relu(self.conv2(secret_image))\n",
    "        output_3 = F.relu(self.conv3(secret_image))\n",
    "\n",
    "        concatenated_image = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "        output_4 = F.relu(self.conv4(concatenated_image))\n",
    "        output_5 = F.relu(self.conv5(concatenated_image))\n",
    "        output_6 = F.relu(self.conv6(concatenated_image))\n",
    "\n",
    "        final_concat_image = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "        return final_concat_image\n",
    "\n",
    "\n",
    "class PrepNetwork2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrepNetwork2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "    def forward(self, secret_image):\n",
    "        output_1 = F.relu(self.conv1(secret_image))\n",
    "        output_2 = F.relu(self.conv2(secret_image))\n",
    "        output_3 = F.relu(self.conv3(secret_image))\n",
    "\n",
    "        concatenated_image = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "        output_4 = F.relu(self.conv4(concatenated_image))\n",
    "        output_5 = F.relu(self.conv5(concatenated_image))\n",
    "        output_6 = F.relu(self.conv6(concatenated_image))\n",
    "\n",
    "        final_concat_image = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "        return final_concat_image\n",
    "\n",
    "\n",
    "class PrepNetwork3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrepNetwork3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "    def forward(self, secret_image):\n",
    "        output_1 = F.relu(self.conv1(secret_image))\n",
    "        output_2 = F.relu(self.conv2(secret_image))\n",
    "        output_3 = F.relu(self.conv3(secret_image))\n",
    "\n",
    "        concatenated_image = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "        output_4 = F.relu(self.conv4(concatenated_image))\n",
    "        output_5 = F.relu(self.conv5(concatenated_image))\n",
    "        output_6 = F.relu(self.conv6(concatenated_image))\n",
    "\n",
    "        final_concat_image = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "        return final_concat_image\n",
    "\n",
    "\n",
    "class HidingNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HidingNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=198, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=198, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=198, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv13 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv14 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv15 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(\n",
    "            in_channels=65, out_channels=3, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "    def forward(self, secret_image_1, secret_image_2, secret_image_3, cover_image):\n",
    "        concatenated_secrets = torch.cat(\n",
    "            [cover_image, secret_image_1, secret_image_2, secret_image_3], dim=1)\n",
    "\n",
    "        output_1 = F.relu(self.conv1(concatenated_secrets))\n",
    "        output_2 = F.relu(self.conv2(concatenated_secrets))\n",
    "        output_3 = F.relu(self.conv3(concatenated_secrets))\n",
    "        concat_1 = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "\n",
    "        output_4 = F.relu(self.conv4(concat_1))\n",
    "        output_5 = F.relu(self.conv5(concat_1))\n",
    "        output_6 = F.relu(self.conv6(concat_1))\n",
    "        concat_2 = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "\n",
    "        output_7 = F.relu(self.conv7(concat_2))\n",
    "        output_8 = F.relu(self.conv8(concat_2))\n",
    "        output_9 = F.relu(self.conv9(concat_2))\n",
    "        concat_3 = torch.cat([output_7, output_8, output_9], dim=1)\n",
    "\n",
    "        output_10 = F.relu(self.conv10(concat_3))\n",
    "        output_11 = F.relu(self.conv11(concat_3))\n",
    "        output_12 = F.relu(self.conv12(concat_3))\n",
    "        concat_4 = torch.cat([output_10, output_11, output_12], dim=1)\n",
    "\n",
    "        output_13 = F.relu(self.conv13(concat_4))\n",
    "        output_14 = F.relu(self.conv14(concat_4))\n",
    "        output_15 = F.relu(self.conv15(concat_4))\n",
    "        concat_5 = torch.cat([output_13, output_14, output_15], dim=1)\n",
    "\n",
    "        output_converted_image = F.relu(self.final_layer(concat_5))\n",
    "\n",
    "        return output_converted_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, prep_network_1, prep_network_2, prep_network_3, hiding_network):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.prep_network1 = prep_network_1\n",
    "        self.prep_network2 = prep_network_2\n",
    "        self.prep_network3 = prep_network_3\n",
    "        self.hiding_network = hiding_network\n",
    "\n",
    "    def forward(self, cover_image, secret_image_1, secret_image_2, secret_image_3):\n",
    "        encoded_secret_image_1 = self.prep_network1(secret_image_1)\n",
    "        encoded_secret_image_2 = self.prep_network2(secret_image_2)\n",
    "        encoded_secret_image_3 = self.prep_network3(secret_image_3)\n",
    "\n",
    "        hidden_image = self.hiding_network(encoded_secret_image_1,\n",
    "                                           encoded_secret_image_2,\n",
    "                                           encoded_secret_image_3,\n",
    "                                           cover_image\n",
    "                                           )\n",
    "#         hidden_image = (0.01**0.5)*torch.randn(hidden_image.size(),device=device)\n",
    "        return hidden_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevealNetwork1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RevealNetwork1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv13 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv14 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv15 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(\n",
    "            in_channels=65, out_channels=3, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "    def forward(self, hidden_image):\n",
    "\n",
    "        output_1 = F.relu(self.conv1(hidden_image))\n",
    "        output_2 = F.relu(self.conv2(hidden_image))\n",
    "        output_3 = F.relu(self.conv3(hidden_image))\n",
    "        concat_1 = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "\n",
    "        output_4 = F.relu(self.conv4(concat_1))\n",
    "        output_5 = F.relu(self.conv5(concat_1))\n",
    "        output_6 = F.relu(self.conv6(concat_1))\n",
    "        concat_2 = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "\n",
    "        output_7 = F.relu(self.conv7(concat_2))\n",
    "        output_8 = F.relu(self.conv8(concat_2))\n",
    "        output_9 = F.relu(self.conv9(concat_2))\n",
    "        concat_3 = torch.cat([output_7, output_8, output_9], dim=1)\n",
    "\n",
    "        output_10 = F.relu(self.conv10(concat_3))\n",
    "        output_11 = F.relu(self.conv11(concat_3))\n",
    "        output_12 = F.relu(self.conv12(concat_3))\n",
    "        concat_4 = torch.cat([output_10, output_11, output_12], dim=1)\n",
    "\n",
    "        output_13 = F.relu(self.conv13(concat_4))\n",
    "        output_14 = F.relu(self.conv14(concat_4))\n",
    "        output_15 = F.relu(self.conv15(concat_4))\n",
    "        concat_5 = torch.cat([output_13, output_14, output_15], dim=1)\n",
    "\n",
    "        output_revealed_image = F.relu(self.final_layer(concat_5))\n",
    "\n",
    "        return output_revealed_image\n",
    "\n",
    "\n",
    "class RevealNetwork2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RevealNetwork2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv13 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv14 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv15 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(\n",
    "            in_channels=65, out_channels=3, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "    def forward(self, hidden_image):\n",
    "\n",
    "        output_1 = F.relu(self.conv1(hidden_image))\n",
    "        output_2 = F.relu(self.conv2(hidden_image))\n",
    "        output_3 = F.relu(self.conv3(hidden_image))\n",
    "        concat_1 = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "\n",
    "        output_4 = F.relu(self.conv4(concat_1))\n",
    "        output_5 = F.relu(self.conv5(concat_1))\n",
    "        output_6 = F.relu(self.conv6(concat_1))\n",
    "        concat_2 = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "\n",
    "        output_7 = F.relu(self.conv7(concat_2))\n",
    "        output_8 = F.relu(self.conv8(concat_2))\n",
    "        output_9 = F.relu(self.conv9(concat_2))\n",
    "        concat_3 = torch.cat([output_7, output_8, output_9], dim=1)\n",
    "\n",
    "        output_10 = F.relu(self.conv10(concat_3))\n",
    "        output_11 = F.relu(self.conv11(concat_3))\n",
    "        output_12 = F.relu(self.conv12(concat_3))\n",
    "        concat_4 = torch.cat([output_10, output_11, output_12], dim=1)\n",
    "\n",
    "        output_13 = F.relu(self.conv13(concat_4))\n",
    "        output_14 = F.relu(self.conv14(concat_4))\n",
    "        output_15 = F.relu(self.conv15(concat_4))\n",
    "        concat_5 = torch.cat([output_13, output_14, output_15], dim=1)\n",
    "\n",
    "        output_revealed_image = F.relu(self.final_layer(concat_5))\n",
    "\n",
    "        return output_revealed_image\n",
    "\n",
    "\n",
    "class RevealNetwork3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RevealNetwork3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=5,\n",
    "                               kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.conv13 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=50, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv14 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=10, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv15 = nn.Conv2d(\n",
    "            in_channels=65, out_channels=5, kernel_size=(5, 5), stride=1, padding=2)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(\n",
    "            in_channels=65, out_channels=3, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "    def forward(self, hidden_image):\n",
    "        output_1 = F.relu(self.conv1(hidden_image))\n",
    "        output_2 = F.relu(self.conv2(hidden_image))\n",
    "        output_3 = F.relu(self.conv3(hidden_image))\n",
    "        concat_1 = torch.cat([output_1, output_2, output_3], dim=1)\n",
    "\n",
    "        output_4 = F.relu(self.conv4(concat_1))\n",
    "        output_5 = F.relu(self.conv5(concat_1))\n",
    "        output_6 = F.relu(self.conv6(concat_1))\n",
    "        concat_2 = torch.cat([output_4, output_5, output_6], dim=1)\n",
    "\n",
    "        output_7 = F.relu(self.conv7(concat_2))\n",
    "        output_8 = F.relu(self.conv8(concat_2))\n",
    "        output_9 = F.relu(self.conv9(concat_2))\n",
    "        concat_3 = torch.cat([output_7, output_8, output_9], dim=1)\n",
    "\n",
    "        output_10 = F.relu(self.conv10(concat_3))\n",
    "        output_11 = F.relu(self.conv11(concat_3))\n",
    "        output_12 = F.relu(self.conv12(concat_3))\n",
    "        concat_4 = torch.cat([output_10, output_11, output_12], dim=1)\n",
    "\n",
    "        output_13 = F.relu(self.conv13(concat_4))\n",
    "        output_14 = F.relu(self.conv14(concat_4))\n",
    "        output_15 = F.relu(self.conv15(concat_4))\n",
    "        concat_5 = torch.cat([output_13, output_14, output_15], dim=1)\n",
    "\n",
    "        output_revealed_image = F.relu(self.final_layer(concat_5))\n",
    "\n",
    "        return output_revealed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, reveal_network_1, reveal_network_2, reveal_network_3):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.reveal_network_1 = reveal_network_1\n",
    "        self.reveal_network_2 = reveal_network_2\n",
    "        self.reveal_network_3 = reveal_network_3\n",
    "\n",
    "    def forward(self, hidden_image):\n",
    "        reveal_image_1 = self.reveal_network_1(hidden_image)\n",
    "        reveal_image_2 = self.reveal_network_2(hidden_image)\n",
    "        reveal_image_3 = self.reveal_network_3(hidden_image)\n",
    "        return reveal_image_1, reveal_image_2, reveal_image_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteganoModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(SteganoModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, cover_image, secret_image_1, secret_image_2, secret_image_3, hidden_image, mode):\n",
    "        if mode == 'full':\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in self.decoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            hidden_image = self.encoder(\n",
    "                cover_image, secret_image_1, secret_image_2, secret_image_3)\n",
    "            reveal_image_1, reveal_image_2, reveal_image_3 = self.decoder(\n",
    "                hidden_image)\n",
    "            return hidden_image, reveal_image_1, reveal_image_2, reveal_image_3\n",
    "        elif mode == 'encoder':\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.decoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            hidden_image = self.encoder(\n",
    "                cover_image, secret_image_1, secret_image_2, secret_image_3)\n",
    "            return hidden_image\n",
    "        elif mode == 'decoder':\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.decoder.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            reveal_image1, reveal_image2, reveal_image3 = self.decoder(\n",
    "                hidden_image)\n",
    "            return reveal_image1, reveal_image2, reveal_image3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SteganoModel(\n",
       "  (encoder): Encoder(\n",
       "    (prep_network1): PrepNetwork1(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (prep_network2): PrepNetwork2(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (prep_network3): PrepNetwork3(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (hiding_network): HidingNetwork(\n",
       "      (conv1): Conv2d(198, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(198, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(198, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv7): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv8): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv9): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv10): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv11): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv12): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv13): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv14): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv15): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (final_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (reveal_network_1): RevealNetwork1(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv7): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv8): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv9): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv10): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv11): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv12): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv13): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv14): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv15): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (final_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (reveal_network_2): RevealNetwork2(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv7): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv8): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv9): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv10): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv11): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv12): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv13): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv14): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv15): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (final_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (reveal_network_3): RevealNetwork3(\n",
       "      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv7): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv8): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv9): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv10): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv11): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv12): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (conv13): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv14): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv15): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (final_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_1 = PrepNetwork1()\n",
    "prep_2 = PrepNetwork2()\n",
    "prep_3 = PrepNetwork3()\n",
    "hiding_network = HidingNetwork()\n",
    "\n",
    "encoder = Encoder(prep_1, prep_2, prep_3, hiding_network)\n",
    "\n",
    "reveal_1 = RevealNetwork1()\n",
    "reveal_2 = RevealNetwork2()\n",
    "reveal_3 = RevealNetwork3()\n",
    "\n",
    "decoder = Decoder(reveal_1, reveal_2, reveal_3)\n",
    "\n",
    "model = SteganoModel(encoder, decoder)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteganoLoss(nn.Module):\n",
    "    def __init__(self, cover_weight, secret_weight):\n",
    "        super(SteganoLoss, self).__init__()\n",
    "        self.cover_weight = cover_weight\n",
    "        self.secret_weight = secret_weight\n",
    "\n",
    "    def forward(self, predicted_cover_image, cover_image,\n",
    "                predicted_secret_image_1, secret_image_1,\n",
    "                predicted_secret_image_2, secret_image_2,\n",
    "                predicted_secret_image_3, secret_image_3):\n",
    "\n",
    "        cover_loss = self.cover_weight * \\\n",
    "            (F.mse_loss(predicted_cover_image, cover_image))\n",
    "        secret_loss = self.secret_weight*(F.mse_loss(predicted_secret_image_1, secret_image_1)) + self.secret_weight*(F.mse_loss(\n",
    "            predicted_secret_image_2, secret_image_2)) + self.secret_weight*(F.mse_loss(predicted_secret_image_3, secret_image_3))\n",
    "        return cover_loss + secret_loss\n",
    "\n",
    "\n",
    "class DecoderLoss(nn.Module):\n",
    "    def __init__(self, decoder_loss_weight):\n",
    "        super(DecoderLoss, self).__init__()\n",
    "        self.decoder_loss_weight = decoder_loss_weight\n",
    "\n",
    "    def forward(self, reveal_output1, reveal_output2, reveal_output3, secret_image_1,\n",
    "                secret_image_2, secret_image_3):\n",
    "        reveal1 = self.decoder_loss_weight * \\\n",
    "            F.mse_loss(reveal_output1, secret_image_1)\n",
    "        reveal2 = self.decoder_loss_weight * \\\n",
    "            F.mse_loss(reveal_output2, secret_image_2)\n",
    "        reveal3 = self.decoder_loss_weight * \\\n",
    "            F.mse_loss(reveal_output3, secret_image_3)\n",
    "\n",
    "        return reveal1 + reveal2 + reveal3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv_path = os.path.join(dataset_path, train_csv)\n",
    "validation_csv_path = os.path.join(dataset_path, valid_csv)\n",
    "\n",
    "training_dataset = SteganoDataset(\n",
    "    training_csv_path, transformations['train_transforms'], 'train', 'complete')\n",
    "valid_dataset = SteganoDataset(\n",
    "    validation_csv_path, transformations['valid_transforms'], 'valid')\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(training_dataset,\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                num_workers=0\n",
    "                                                )\n",
    "valid_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                                batch_size=VALID_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                num_workers=0\n",
    "                                                )\n",
    "\n",
    "full_model_criterion = SteganoLoss(SECRET_LOSS_WEIGHT, COVER_LOSS_WEIGHT)\n",
    "\n",
    "full_model_optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "decoder_criterion = DecoderLoss(DECODER_LOSS_WEIGHT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, decoder_criterion, full_model_optimizer, full_model_criterion, learning_rate, training_iterator, valid_iterator, print_every=50):\n",
    "\n",
    "    training_full_model_loss_list = []\n",
    "    decoder_loss_list = []\n",
    "    valid_loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for index, training_dict in enumerate(training_iterator):\n",
    "            cover_image = training_dict['cover_image']\n",
    "            cover_image = cover_image.to(device)\n",
    "\n",
    "            secret_image_1 = training_dict['secret_image_1']\n",
    "            secret_image_1 = secret_image_1.to(device)\n",
    "\n",
    "            secret_image_2 = training_dict['secret_image_2']\n",
    "            secret_image_2 = secret_image_2.to(device)\n",
    "\n",
    "            secret_image_3 = training_dict['secret_image_3']\n",
    "            secret_image_3 = secret_image_3.to(device)\n",
    "\n",
    "            full_model_optimizer.zero_grad()\n",
    "\n",
    "            encoder_output = model(\n",
    "                cover_image, secret_image_1, secret_image_2, secret_image_3, secret_image_3, 'encoder')\n",
    "\n",
    "            hidden_image, reveal_image_1, reveal_image_2, reveal_image_3 = model(cover_image,\n",
    "                                                                                 secret_image_1,\n",
    "                                                                                 secret_image_2,\n",
    "                                                                                 secret_image_3, secret_image_3, 'full')\n",
    "\n",
    "            full_model_loss = full_model_criterion(hidden_image, cover_image,\n",
    "                                                   reveal_image_1, secret_image_1,\n",
    "                                                   reveal_image_2, secret_image_2,\n",
    "                                                   reveal_image_3, secret_image_3,\n",
    "                                                   )\n",
    "            full_model_loss.backward()\n",
    "            full_model_optimizer.step()\n",
    "\n",
    "            full_model_optimizer.zero_grad()\n",
    "            reveal_output1, reveal_output2, reveal_output3 = model(cover_image,\n",
    "                                                                   secret_image_1,\n",
    "                                                                   secret_image_2,\n",
    "                                                                   secret_image_3, encoder_output, 'decoder')\n",
    "            decoder_loss = decoder_criterion(reveal_output1, reveal_output2, reveal_output3, secret_image_1,\n",
    "                                             secret_image_2, secret_image_3)\n",
    "\n",
    "            decoder_loss.backward()\n",
    "            full_model_optimizer.step()\n",
    "\n",
    "        training_full_model_loss_list.append(full_model_loss)\n",
    "        decoder_loss_list.append(decoder_loss)\n",
    "        if epoch % print_every == 0:\n",
    "            print(\"Training full model loss at {} epochs is: {}\".format(\n",
    "                epoch, full_model_loss))\n",
    "            print(\"Training decoder loss at {} epochs is: {}\".format(\n",
    "                epoch, decoder_loss))\n",
    "\n",
    "    return model, training_full_model_loss_list, decoder_loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'D:\\\\Python Programs\\\\Datasets\\\\imagenette2-320\\noisy_imagenette.csv\\\\train\\\\n03888257_10639.JPEG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13440/3304350451.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model, training_full_model_loss_list, decoder_loss_list = train(\n\u001b[0m\u001b[0;32m      2\u001b[0m     model, EPOCHS, decoder_criterion, full_model_optimizer, full_model_criterion, LEARNING_RATE, train_data_loader, valid_data_loader)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13440/1318503627.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, decoder_criterion, full_model_optimizer, full_model_criterion, learning_rate, training_iterator, valid_iterator, print_every)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_dict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mcover_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cover_image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mcover_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcover_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13440/1465438336.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0msecret_image3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'secret_image_3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mcover_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcover_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0msecret_image1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msecret_image1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0msecret_image2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msecret_image2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2967\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2968\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2969\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'D:\\\\Python Programs\\\\Datasets\\\\imagenette2-320\\noisy_imagenette.csv\\\\train\\\\n03888257_10639.JPEG'"
     ]
    }
   ],
   "source": [
    "model, training_full_model_loss_list, decoder_loss_list = train(\n",
    "    model, EPOCHS, decoder_criterion, full_model_optimizer, full_model_criterion, LEARNING_RATE, train_data_loader, valid_data_loader)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c66f6a286164178c61090f11fff7531913209fa14f0a93186ebc32286e28675"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
